{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Dataloader Class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from catalyst import dl, utils\n",
    "from catalyst.core.logger import ILogger\n",
    "from catalyst.loggers.console import ConsoleLogger\n",
    "from IPython.display import clear_output\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from typing import Dict\n",
    "from utils.dataloaderClass import CMAPSS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "cmapss = CMAPSS('../CMAPSSData/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split train and validation data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def subset_ind(dataset, ratio: float):\n",
    "    return np.random.choice(len(dataset), size=int(ratio*len(dataset)), replace=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "shrink_inds = subset_ind(cmapss, 0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4126\n"
     ]
    }
   ],
   "source": [
    "cmapss_subset = Subset(cmapss, shrink_inds)\n",
    "print(f'Dataset size: {len(cmapss_subset)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "val_inds = subset_ind(cmapss, val_size)\n",
    "\n",
    "train_dataset = Subset(cmapss, [i for i in range(len(cmapss)) if i not in val_inds])\n",
    "val_dataset = Subset(cmapss, val_inds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 16505\n",
      "Validation size: 4126\n"
     ]
    }
   ],
   "source": [
    "print(f'Training size: {len(train_dataset)}\\nValidation size: {len(val_dataset)}')\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Network\n",
    "dim_in, dim_out = 16, 16\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(dim_in, dim_out),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "model.to(device, torch.float32)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Catalyst"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def _format_metrics(dct: Dict):\n",
    "    return \" | \".join([f\"{k}: {float(dct[k]):.03}\" for k in sorted(dct.keys())])\n",
    "\n",
    "\n",
    "class CustomLogger(ConsoleLogger):\n",
    "    \"\"\"Custom console logger for parameters and metrics.\n",
    "    Output the metric into the console during experiment.\n",
    "\n",
    "    Note:\n",
    "        We inherit ConsoleLogger to overwrite default Catalyst logging behaviour\n",
    "    \"\"\"\n",
    "\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        metrics: Dict[str, float],\n",
    "        scope: str = None,\n",
    "        # experiment info\n",
    "        run_key: str = None,\n",
    "        global_epoch_step: int = 0,\n",
    "        global_batch_step: int = 0,\n",
    "        global_sample_step: int = 0,\n",
    "        # stage info\n",
    "        stage_key: str = None,\n",
    "        stage_epoch_len: int = 0,\n",
    "        stage_epoch_step: int = 0,\n",
    "        stage_batch_step: int = 0,\n",
    "        stage_sample_step: int = 0,\n",
    "        # loader info\n",
    "        loader_key: str = None,\n",
    "        loader_batch_len: int = 0,\n",
    "        loader_sample_len: int = 0,\n",
    "        loader_batch_step: int = 0,\n",
    "        loader_sample_step: int = 0,\n",
    "    ) -> None:\n",
    "        \"\"\"Logs loader and epoch metrics to stdout.\"\"\"\n",
    "        if scope == \"loader\":\n",
    "            prefix = f\"{loader_key} ({stage_epoch_step}/{stage_epoch_len}) \"\n",
    "            print(prefix + _format_metrics(metrics))\n",
    "\n",
    "        elif scope == \"epoch\":\n",
    "            prefix = f\"* Epoch ({stage_epoch_step}/{stage_epoch_len}) \"\n",
    "            print(prefix + _format_metrics(metrics[\"_epoch_\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    # TODO put train=false for val data insicde cmapss class\n",
    "    \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "    \"valid\": DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner(\n",
    "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engine': <catalyst.engines.torch.CPUEngine object at 0x2ac69b100>, 'loggers': {'console': <__main__.CustomLogger object at 0x2ac69b9d0>, '_csv': <catalyst.loggers.csv.CSVLogger object at 0x2ac698670>, '_tensorboard': <catalyst.loggers.tensorboard.TensorboardLogger object at 0x2ac2a1090>}, 'loaders': {'train': <accelerate.data_loader.DataLoaderShard object at 0x2ac69b400>, 'valid': <accelerate.data_loader.DataLoaderShard object at 0x2ac68dab0>}, 'model': Sequential(\n",
      "  (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (1): Sigmoid()\n",
      "), 'criterion': CrossEntropyLoss(), 'optimizer': AcceleratedOptimizer (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), 'scheduler': None, 'callbacks': OrderedDict([(0, <catalyst.callbacks.metrics.accuracy.AccuracyCallback object at 0x2ac698040>), (1, <catalyst.callbacks.metrics.classification.PrecisionRecallF1SupportCallback object at 0x2ac69a140>), ('_criterion', <catalyst.callbacks.criterion.CriterionCallback object at 0x2ac69a8f0>), ('_backward', <catalyst.callbacks.backward.BackwardCallback object at 0x2ac68c160>), ('_optimizer', <catalyst.callbacks.optimizer.OptimizerCallback object at 0x2ac68ebc0>), ('_checkpoint', <catalyst.callbacks.checkpoint.CheckpointCallback object at 0x2ac68c730>), ('_verbose', <catalyst.callbacks.misc.TqdmCallback object at 0x105e27490>)]), 'batch': None, 'batch_metrics': defaultdict(None, {}), 'loader_metrics': defaultdict(None, {}), 'epoch_metrics': defaultdict(None, {'_epoch_': {}}), 'experiment_metrics': defaultdict(None, {}), 'epoch_step': 1, 'batch_step': 0, 'sample_step': 0, 'loader': <accelerate.data_loader.DataLoaderShard object at 0x2ac69b400>, 'loader_key': 'train', 'is_train_loader': True, 'is_valid_loader': False, 'is_infer_loader': False, 'loader_batch_size': 32, 'loader_batch_len': 516, 'loader_sample_len': 16505, 'loader_batch_step': 0, 'loader_sample_step': 0, 'batch_size': 0, 'exception': KeyError(16486), 'need_early_stop': False, '_local_rank': -1, '_world_size': 1, '_input_key': 'features', '_output_key': 'labels', '_target_key': 'RUL', '_loss_key': 'loss', '_process_input': <bound method ISupervisedRunner._process_input_str of <catalyst.runners.supervised.SupervisedRunner object at 0x2ac699540>>, '_process_output': <bound method ISupervisedRunner._process_output_str of <catalyst.runners.supervised.SupervisedRunner object at 0x2ac699540>>, '_seed': 42, '_hparams': None, '_num_epochs': 6, '_logdir': './logs', '_valid_loader': 'valid', '_valid_metric': 'loss', '_minimize_valid_metric': True, '_resume': None, '_verbose': True, '_timeit': False, '_check': False, '_overfit': False, '_profile': False, '_load_best_on_end': True, '_engine': <catalyst.engines.torch.CPUEngine object at 0x2ac69b100>, '_loggers': {'console': <__main__.CustomLogger object at 0x2ac69b9d0>, '_csv': <catalyst.loggers.csv.CSVLogger object at 0x2ac698670>, '_tensorboard': <catalyst.loggers.tensorboard.TensorboardLogger object at 0x2ac2a1090>}, '_loaders': {'train': <torch.utils.data.dataloader.DataLoader object at 0x2ac69a230>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x2ac699ea0>}, '_model': Sequential(\n",
      "  (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (1): Sigmoid()\n",
      "), '_criterion': CrossEntropyLoss(), '_optimizer': Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), '_scheduler': None, '_callbacks': [<catalyst.callbacks.metrics.accuracy.AccuracyCallback object at 0x2ac698040>, <catalyst.callbacks.metrics.classification.PrecisionRecallF1SupportCallback object at 0x2ac69a140>]}\n"
     ]
    }
   ],
   "source": [
    "print(runner.__dict__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "1/6 * Epoch (train):   0%|          | 0/516 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f73e4645a1494e9f877986c47f12e1e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "16486",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 16486",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [64], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# model training\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloggers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconsole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mCustomLogger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAccuracyCallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogits\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtargets\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPrecisionRecallF1SupportCallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRUL\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./logs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mloss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mminimize_valid_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mload_best_on_end\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/runners/runner.py:377\u001B[0m, in \u001B[0;36mRunner.train\u001B[0;34m(self, loaders, model, engine, criterion, optimizer, scheduler, callbacks, loggers, seed, hparams, num_epochs, logdir, resume, valid_loader, valid_metric, minimize_valid_metric, verbose, timeit, check, overfit, profile, load_best_on_end, cpu, fp16, ddp)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_best_on_end \u001B[38;5;241m=\u001B[39m load_best_on_end\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# run\u001B[39;00m\n\u001B[0;32m--> 377\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:422\u001B[0m, in \u001B[0;36mIRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception \u001B[38;5;241m=\u001B[39m ex\n\u001B[0;32m--> 422\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_event\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mon_exception\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:365\u001B[0m, in \u001B[0;36mIRunner._run_event\u001B[0;34m(self, event)\u001B[0m\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;28mgetattr\u001B[39m(callback, event)(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_str_intersections(event, (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_end\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_exception\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:357\u001B[0m, in \u001B[0;36mIRunner.on_exception\u001B[0;34m(self, runner)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_exception\u001B[39m(\u001B[38;5;28mself\u001B[39m, runner: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIRunner\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    356\u001B[0m     \u001B[38;5;124;03m\"\"\"Event handler.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 357\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:419\u001B[0m, in \u001B[0;36mIRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;124;03m\"\"\"Runs the experiment.\u001B[39;00m\n\u001B[1;32m    414\u001B[0m \n\u001B[1;32m    415\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;124;03m    self, `IRunner` instance after the experiment\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception \u001B[38;5;241m=\u001B[39m ex\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:410\u001B[0m, in \u001B[0;36mIRunner._run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    409\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_engine()\n\u001B[0;32m--> 410\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspawn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_local\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/engine.py:59\u001B[0m, in \u001B[0;36mEngine.spawn\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mspawn\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn: Callable, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;124;03m\"\"\"Spawns processes with specified ``fn`` and ``args``/``kwargs``.\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m        wrapped function (if needed).\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:405\u001B[0m, in \u001B[0;36mIRunner._run_local\u001B[0;34m(self, local_rank, world_size)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_local_rank, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_world_size \u001B[38;5;241m=\u001B[39m local_rank, world_size\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_experiment_start\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 405\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_experiment_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:399\u001B[0m, in \u001B[0;36mIRunner._run_experiment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_epoch_start\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 399\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_epoch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:391\u001B[0m, in \u001B[0;36mIRunner._run_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaders\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_loader_start\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 391\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_loader_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/catalyst/core/runner.py:380\u001B[0m, in \u001B[0;36mIRunner._run_loader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_loader\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_train_loader):\n\u001B[0;32m--> 380\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneed_early_stop:\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneed_early_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/accelerate/data_loader.py:376\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     current_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[0;32m--> 295\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/Dropbox/dev/thesis/utils/dataloaderClass.py:22\u001B[0m, in \u001B[0;36mCMAPSS.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[0;32m---> 22\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     23\u001B[0m     label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[index]\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/pandas/core/frame.py:3804\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3804\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3806\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/.conda/envs/rul-torch/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 16486"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    loggers={\"console\": CustomLogger()},\n",
    "    num_epochs=6,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk=(1, 3, 5)),\n",
    "        dl.PrecisionRecallF1SupportCallback(input_key=\"labels\", target_key=\"RUL\"),\n",
    "    ],\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "metrics = runner.evaluate_loader(\n",
    "    loader=loaders[\"valid\"],\n",
    "    callbacks=[dl.AccuracyCallback(input_key=\"labels\", target_key=\"RUL\", topk=(1, 3, 5))],\n",
    ")\n",
    "\n",
    "# model inference\n",
    "for prediction in runner.predict_loader(loader=loaders[\"valid\"]):\n",
    "    assert prediction[\"labels\"].detach().cpu().numpy().shape[-1] == 10\n",
    "\n",
    "# model post-processing\n",
    "model = runner.model.cpu()\n",
    "batch = next(iter(loaders[\"valid\"]))[0]\n",
    "utils.trace_model(model=model, batch=batch)\n",
    "utils.quantize_model(model=model)\n",
    "utils.prune_model(model=model, pruning_fn=\"l1_unstructured\", amount=0.8)\n",
    "utils.onnx_export(model=model, batch=batch, file=\"./logs/cmapss.onnx\", verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also need some validation code to reload the best checkpoint, evaluate it using our validation data and compute metrics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def infer(model):\n",
    "    \"\"\"Fully turns model state to inference (and restores it in the end)\"\"\"\n",
    "    status = model.training\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            yield None\n",
    "        finally:\n",
    "            model.train(status)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def load_ckpt(path, model, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Load saved checkpoint weights to model\n",
    "    :param path: full path to checkpoint\n",
    "    :param model: initialized model class nested from nn.Module()\n",
    "    :param device: base torch device for validation\n",
    "    :return: model with loaded 'state_dict'\n",
    "    \"\"\"\n",
    "    assert os.path.isfile(path), FileNotFoundError(f\"no file: {path}\")\n",
    "\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    ckpt_dict = ckpt[\"model_state_dict\"]\n",
    "    model_dict = model.state_dict()\n",
    "    ckpt_dict = {k: v for k, v in ckpt_dict.items() if k in model_dict}\n",
    "    model_dict.update(ckpt_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_model(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate implemented model\n",
    "    :param model: initialized model class nested from nn.Module() with loaded state dict\n",
    "    :param loader batch data loader for evaluation set\n",
    "    :param device: base torch device for validation\n",
    "    :return: dict performance metrics\n",
    "    \"\"\"\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    model.train(False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for data_tensor, lbl_tensor in loader:\n",
    "        lbl_values = lbl_tensor.cpu().view(-1).tolist()\n",
    "        label_list.extend(lbl_values)\n",
    "        logits = model(data_tensor.to(device))\n",
    "        scores = F.softmax(logits.detach().cpu(), 1).numpy()\n",
    "        pred_labels = np.argmax(scores, 1)\n",
    "        pred_list.extend(pred_labels.ravel().tolist())\n",
    "\n",
    "    labels = np.array(label_list)\n",
    "    predicted = np.array(pred_list)\n",
    "    acc = accuracy_score(labels, predicted)\n",
    "    print(f\"model accuracy: {acc:.4f}\")\n",
    "    metric_dict = {\"accuracy\": acc}\n",
    "    return metric_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test it: first we re-initialize the model and load the checkpoint state dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ckpt_fp = os.path.join(\"logs\", \"checkpoints\", \"best.pth\")  # \"last.pth\", \"epoch01.pth\" ...\n",
    "mod = BaseModel(num_classes=num_classes)\n",
    "mod = load_ckpt(ckpt_fp, mod).eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can run validation code using the corresponding data loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_runner = validate_model(mod, loaders[\"valid\"], device)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
