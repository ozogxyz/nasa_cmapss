{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10bd65170>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rul_datasets\n",
    "import torch\n",
    "import warnings\n",
    "from catalyst import dl, utils\n",
    "from torch import nn, optim\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Shcherbakov(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        # CNN feature extraction part\n",
    "        self.feature_extractor = nn.Sequential()\n",
    "        self.feature_extractor.add_module(\n",
    "            'Conv1d_1', nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        )\n",
    "        self.feature_extractor.add_module('ReLU_1', nn.ReLU())\n",
    "        self.feature_extractor.add_module(\n",
    "            'Conv1d_2', nn.Conv1d(out_channels, out_channels * 2, kernel_size - 2)\n",
    "        )\n",
    "        self.feature_extractor.add_module('ReLU_2', nn.ReLU())\n",
    "        self.feature_extractor.add_module('Flatten', nn.Flatten(start_dim=1))\n",
    "        self.feature_extractor.add_module(\n",
    "            'MaxPool1d', nn.MaxPool1d(kernel_size=3)\n",
    "        )\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(input_size=48, hidden_size=96, num_layers=50)\n",
    "        self.lstm_2 = nn.LSTM(input_size=96, hidden_size=96, num_layers=50)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.num_layers = 50\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # Regressor part\n",
    "        self.regressor = nn.Sequential()\n",
    "        self.regressor.add_module('Linear_1', nn.Linear(48, 1))\n",
    "        self.regressor.add_module('ReLU_2', nn.ReLU())\n",
    "\n",
    "        # Loss function\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, time_series):\n",
    "        # CNN feature extraction\n",
    "        features = self.feature_extractor(time_series)\n",
    "\n",
    "        # LSTM layers\n",
    "        h_0 = torch.zeros(self.num_layers, 96)\n",
    "        c_0 = torch.zeros(self.num_layers, 96)\n",
    "        output, (h_n, c_n) = self.lstm_1(features, (h_0, c_0))\n",
    "        output = self.tanh(self.dropout(output))\n",
    "        output, (h_n, c_n) = self.lstm_2(output, (h_n, c_n))\n",
    "        output = self.tanh(self.dropout(output))\n",
    "        preds = self.regressor(features)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "cmapss_fd1 = rul_datasets.CmapssReader(fd=1)\n",
    "dm = rul_datasets.RulDataModule(cmapss_fd1, batch_size=32)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        return torch.sqrt(self.mse(predictions, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sqrt(): argument 'input' (position 1) must be Tensor, not MSELoss",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m model \u001B[39m=\u001B[39m Shcherbakov(in_channels\u001B[39m=\u001B[39m\u001B[39m14\u001B[39m, out_channels\u001B[39m=\u001B[39m\u001B[39m3\u001B[39m, kernel_size\u001B[39m=\u001B[39m\u001B[39m5\u001B[39m)\n\u001B[1;32m      3\u001B[0m criterion \u001B[39m=\u001B[39m nn\u001B[39m.\u001B[39mMSELoss()\n\u001B[0;32m----> 4\u001B[0m RMSE_loss \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39;49msqrt(criterion)\n\u001B[1;32m      5\u001B[0m optimizer \u001B[39m=\u001B[39m optim\u001B[39m.\u001B[39mAdam(model\u001B[39m.\u001B[39mparameters(), lr\u001B[39m=\u001B[39m\u001B[39m0.02\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: sqrt(): argument 'input' (position 1) must be Tensor, not MSELoss"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Shcherbakov(in_channels=14, out_channels=3, kernel_size=5)\n",
    "criterion = nn.MSELoss()\n",
    "RMSE_loss = torch.sqrt(criterion)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    \"train\": dm.train_dataloader(),\n",
    "    \"val\": dm.val_dataloader(),\n",
    "    \"test\": dm.test_dataloader(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner(\n",
    "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f05ce7235b4af0a1aac8d690f6242a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/1 * Epoch (train):   0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1/1) accuracy01: 0.0 | accuracy01/std: 0.0 | accuracy03: 0.0 | accuracy03/std: 0.0 | accuracy05: 0.0 | accuracy05/std: 0.0 | f1/_macro: 0.0 | f1/_micro: 0.0 | f1/_weighted: 0.0 | loss: 1977.2614941505196 | loss/mean: 1977.2614941505196 | loss/std: 1075.9956441243228 | lr: 0.02 | momentum: 0.9 | precision/_macro: 0.0 | precision/_micro: 0.0 | precision/_weighted: 0.0 | recall/_macro: 0.0 | recall/_micro: 0.0 | recall/_weighted: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[39m# model training\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m runner\u001B[39m.\u001B[39;49mtrain(\n\u001B[1;32m      3\u001B[0m     model\u001B[39m=\u001B[39;49mmodel,\n\u001B[1;32m      4\u001B[0m     criterion\u001B[39m=\u001B[39;49mcriterion,\n\u001B[1;32m      5\u001B[0m     optimizer\u001B[39m=\u001B[39;49moptimizer,\n\u001B[1;32m      6\u001B[0m     loaders\u001B[39m=\u001B[39;49mloaders,\n\u001B[1;32m      7\u001B[0m     num_epochs\u001B[39m=\u001B[39;49m\u001B[39m1\u001B[39;49m,\n\u001B[1;32m      8\u001B[0m     callbacks\u001B[39m=\u001B[39;49m[\n\u001B[1;32m      9\u001B[0m         dl\u001B[39m.\u001B[39;49mAccuracyCallback(input_key\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mlogits\u001B[39;49m\u001B[39m\"\u001B[39;49m, target_key\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mtargets\u001B[39;49m\u001B[39m\"\u001B[39;49m, topk\u001B[39m=\u001B[39;49m(\u001B[39m1\u001B[39;49m, \u001B[39m3\u001B[39;49m, \u001B[39m5\u001B[39;49m)),\n\u001B[1;32m     10\u001B[0m         dl\u001B[39m.\u001B[39;49mPrecisionRecallF1SupportCallback(input_key\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mlogits\u001B[39;49m\u001B[39m\"\u001B[39;49m, target_key\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mtargets\u001B[39;49m\u001B[39m\"\u001B[39;49m),\n\u001B[1;32m     11\u001B[0m     ],\n\u001B[1;32m     12\u001B[0m     logdir\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39m./logs\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[1;32m     13\u001B[0m     valid_loader\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mvalid\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[1;32m     14\u001B[0m     valid_metric\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mloss\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[1;32m     15\u001B[0m     minimize_valid_metric\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m,\n\u001B[1;32m     16\u001B[0m     verbose\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m,\n\u001B[1;32m     17\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/runners/runner.py:377\u001B[0m, in \u001B[0;36mRunner.train\u001B[0;34m(self, loaders, model, engine, criterion, optimizer, scheduler, callbacks, loggers, seed, hparams, num_epochs, logdir, resume, valid_loader, valid_metric, minimize_valid_metric, verbose, timeit, check, overfit, profile, load_best_on_end, cpu, fp16, ddp)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_load_best_on_end \u001B[39m=\u001B[39m load_best_on_end\n\u001B[1;32m    376\u001B[0m \u001B[39m# run\u001B[39;00m\n\u001B[0;32m--> 377\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mrun()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:422\u001B[0m, in \u001B[0;36mIRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    420\u001B[0m \u001B[39mexcept\u001B[39;00m (\u001B[39mException\u001B[39;00m, \u001B[39mKeyboardInterrupt\u001B[39;00m) \u001B[39mas\u001B[39;00m ex:\n\u001B[1;32m    421\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexception \u001B[39m=\u001B[39m ex\n\u001B[0;32m--> 422\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_run_event(\u001B[39m\"\u001B[39;49m\u001B[39mon_exception\u001B[39;49m\u001B[39m\"\u001B[39;49m)\n\u001B[1;32m    423\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:365\u001B[0m, in \u001B[0;36mIRunner._run_event\u001B[0;34m(self, event)\u001B[0m\n\u001B[1;32m    363\u001B[0m     \u001B[39mgetattr\u001B[39m(callback, event)(\u001B[39mself\u001B[39m)\n\u001B[1;32m    364\u001B[0m \u001B[39mif\u001B[39;00m is_str_intersections(event, (\u001B[39m\"\u001B[39m\u001B[39m_end\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39m_exception\u001B[39m\u001B[39m\"\u001B[39m)):\n\u001B[0;32m--> 365\u001B[0m     \u001B[39mgetattr\u001B[39;49m(\u001B[39mself\u001B[39;49m, event)(\u001B[39mself\u001B[39;49m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:357\u001B[0m, in \u001B[0;36mIRunner.on_exception\u001B[0;34m(self, runner)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mon_exception\u001B[39m(\u001B[39mself\u001B[39m, runner: \u001B[39m\"\u001B[39m\u001B[39mIRunner\u001B[39m\u001B[39m\"\u001B[39m):\n\u001B[1;32m    356\u001B[0m     \u001B[39m\"\"\"Event handler.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 357\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexception\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:419\u001B[0m, in \u001B[0;36mIRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[39m\"\"\"Runs the experiment.\u001B[39;00m\n\u001B[1;32m    414\u001B[0m \n\u001B[1;32m    415\u001B[0m \u001B[39mReturns:\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[39m    self, `IRunner` instance after the experiment\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m--> 419\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_run()\n\u001B[1;32m    420\u001B[0m \u001B[39mexcept\u001B[39;00m (\u001B[39mException\u001B[39;00m, \u001B[39mKeyboardInterrupt\u001B[39;00m) \u001B[39mas\u001B[39;00m ex:\n\u001B[1;32m    421\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexception \u001B[39m=\u001B[39m ex\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:410\u001B[0m, in \u001B[0;36mIRunner._run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_run\u001B[39m(\u001B[39mself\u001B[39m) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    409\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mengine \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mget_engine()\n\u001B[0;32m--> 410\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mengine\u001B[39m.\u001B[39;49mspawn(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_run_local)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/engine.py:59\u001B[0m, in \u001B[0;36mEngine.spawn\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mspawn\u001B[39m(\u001B[39mself\u001B[39m, fn: Callable, \u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[39m\"\"\"Spawns processes with specified ``fn`` and ``args``/``kwargs``.\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \n\u001B[1;32m     45\u001B[0m \u001B[39m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[39m        wrapped function (if needed).\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m     \u001B[39mreturn\u001B[39;00m fn(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:405\u001B[0m, in \u001B[0;36mIRunner._run_local\u001B[0;34m(self, local_rank, world_size)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_local_rank, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_world_size \u001B[39m=\u001B[39m local_rank, world_size\n\u001B[1;32m    404\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_run_event(\u001B[39m\"\u001B[39m\u001B[39mon_experiment_start\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m--> 405\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_run_experiment()\n\u001B[1;32m    406\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_run_event(\u001B[39m\"\u001B[39m\u001B[39mon_experiment_end\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:399\u001B[0m, in \u001B[0;36mIRunner._run_experiment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[39mbreak\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_run_event(\u001B[39m\"\u001B[39m\u001B[39mon_epoch_start\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m--> 399\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_run_epoch()\n\u001B[1;32m    400\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_run_event(\u001B[39m\"\u001B[39m\u001B[39mon_epoch_end\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:390\u001B[0m, in \u001B[0;36mIRunner._run_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_run_epoch\u001B[39m(\u001B[39mself\u001B[39m) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    389\u001B[0m     \u001B[39mfor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader_key, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloaders\u001B[39m.\u001B[39mitems():\n\u001B[0;32m--> 390\u001B[0m         \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_run_event(\u001B[39m\"\u001B[39;49m\u001B[39mon_loader_start\u001B[39;49m\u001B[39m\"\u001B[39;49m)\n\u001B[1;32m    391\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_run_loader()\n\u001B[1;32m    392\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_run_event(\u001B[39m\"\u001B[39m\u001B[39mon_loader_end\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:361\u001B[0m, in \u001B[0;36mIRunner._run_event\u001B[0;34m(self, event)\u001B[0m\n\u001B[1;32m    359\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_run_event\u001B[39m(\u001B[39mself\u001B[39m, event: \u001B[39mstr\u001B[39m) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    360\u001B[0m     \u001B[39mif\u001B[39;00m is_str_intersections(event, (\u001B[39m\"\u001B[39m\u001B[39m_start\u001B[39m\u001B[39m\"\u001B[39m,)):\n\u001B[0;32m--> 361\u001B[0m         \u001B[39mgetattr\u001B[39;49m(\u001B[39mself\u001B[39;49m, event)(\u001B[39mself\u001B[39;49m)\n\u001B[1;32m    362\u001B[0m     \u001B[39mfor\u001B[39;00m callback \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mcallbacks\u001B[39m.\u001B[39mvalues():\n\u001B[1;32m    363\u001B[0m         \u001B[39mgetattr\u001B[39m(callback, event)(\u001B[39mself\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/catalyst/lib/python3.10/site-packages/catalyst/core/runner.py:300\u001B[0m, in \u001B[0;36mIRunner.on_loader_start\u001B[0;34m(self, runner)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mis_valid_loader: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader_key\u001B[39m.\u001B[39mstartswith(\u001B[39m\"\u001B[39m\u001B[39mvalid\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m    299\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mis_infer_loader: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader_key\u001B[39m.\u001B[39mstartswith(\u001B[39m\"\u001B[39m\u001B[39minfer\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m--> 300\u001B[0m \u001B[39massert\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mis_train_loader \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mis_valid_loader \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mis_infer_loader\n\u001B[1;32m    301\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader_batch_size: \u001B[39mint\u001B[39m \u001B[39m=\u001B[39m get_loader_batch_size(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader)\n\u001B[1;32m    302\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader_batch_len: \u001B[39mint\u001B[39m \u001B[39m=\u001B[39m \u001B[39mlen\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mloader)\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    num_epochs=1,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk=(1, 3, 5)),\n",
    "        dl.PrecisionRecallF1SupportCallback(input_key=\"logits\", target_key=\"targets\"),\n",
    "    ],\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = torch.inf\n",
    "for epoch in range(10):\n",
    "    print(f\"Train epoch {epoch}\")\n",
    "    model.train()\n",
    "    for features, targets in dm.train_dataloader():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(features)\n",
    "        loss = torch.sqrt(torch.mean((targets - predictions)**2)) # (4)!\n",
    "        loss.backward()\n",
    "        print(f\"Epoch: {epoch}\\tTraining loss: {loss}\")\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Validate epoch {epoch}\")\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_samples = 0\n",
    "    for features, targets in dm.val_dataloader():\n",
    "        predictions = model(features)\n",
    "        loss = torch.sum((targets - predictions)**2)\n",
    "        val_loss += loss.detach()\n",
    "        num_samples += predictions.shape[0]\n",
    "    val_loss = torch.sqrt(val_loss / num_samples) # (5)!\n",
    "\n",
    "    if best_val_loss < val_loss:\n",
    "        break\n",
    "    else:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"Validation loss: {best_val_loss}\")\n",
    "\n",
    "test_loss = 0\n",
    "num_samples = 0\n",
    "for features, targets in dm.test_dataloader():\n",
    "    predictions = model(features)\n",
    "    loss = torch.sqrt(torch.dist(predictions, targets))\n",
    "    test_loss += loss.detach()\n",
    "    num_samples += predictions.shape[0]\n",
    "test_loss = torch.sqrt(test_loss / num_samples) # (6)!\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('catalyst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "faa49532528bb5676b2a6b6e41d3f7e247db341dc60dbf3704c420a2de4a30a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
